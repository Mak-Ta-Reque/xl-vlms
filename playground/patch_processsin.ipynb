{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "11936.17s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch==2.4.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: torchvision==0.19.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (0.19.1+cu124)\n",
      "Requirement already satisfied: filelock in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1) (3.0.0)\n",
      "Requirement already satisfied: numpy in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torchvision==0.19.1) (2.2.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torchvision==0.19.1) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from jinja2->torch==2.4.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from sympy->torch==2.4.1) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install torch==2.4.1 torchvision==0.19.1 --extra-index-url https://download.pytorch.org/whl/cu124\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "11945.69s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/luca-medeiros/lang-segment-anything.git\n",
      "  Cloning https://github.com/luca-medeiros/lang-segment-anything.git to /tmp/pip-req-build-1i280pnh\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/luca-medeiros/lang-segment-anything.git /tmp/pip-req-build-1i280pnh\n",
      "  Resolved https://github.com/luca-medeiros/lang-segment-anything.git to commit 19cb3670caea21e11b35e01ce1115a4a35b27fb5\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sam-2@ git+https://github.com/facebookresearch/segment-anything-2@c2ec8e14a185632b0a5d8b161928ceb50197eddc (from lang-sam==0.2.1)\n",
      "  Using cached SAM_2-1.0-cp311-cp311-linux_x86_64.whl\n",
      "Requirement already satisfied: gradio==5.0.2 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from lang-sam==0.2.1) (5.0.2)\n",
      "Requirement already satisfied: litserve==0.2.3 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from lang-sam==0.2.1) (0.2.3)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from lang-sam==0.2.1) (4.10.0.84)\n",
      "Requirement already satisfied: pydantic==2.9.2 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from lang-sam==0.2.1) (2.9.2)\n",
      "Requirement already satisfied: supervision==0.23.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from lang-sam==0.2.1) (0.23.0)\n",
      "Requirement already satisfied: transformers==4.44.2 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from lang-sam==0.2.1) (4.44.2)\n",
      "Requirement already satisfied: uvloop==0.20.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from lang-sam==0.2.1) (0.20.0)\n",
      "Requirement already satisfied: torch==2.4.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from lang-sam==0.2.1) (2.4.1+cu124)\n",
      "Requirement already satisfied: torchvision==0.19.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from lang-sam==0.2.1) (0.19.1+cu124)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (4.8.0)\n",
      "Requirement already satisfied: fastapi<1.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (0.115.8)\n",
      "Requirement already satisfied: ffmpy in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.4.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (1.4.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (3.1.5)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (2.2.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (3.10.15)\n",
      "Requirement already satisfied: packaging in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (2.2.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (10.4.0)\n",
      "Requirement already satisfied: pydub in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (0.9.4)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio==5.0.2->lang-sam==0.2.1) (0.34.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from pydantic==2.9.2->lang-sam==0.2.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from pydantic==2.9.2->lang-sam==0.2.1) (2.23.4)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from supervision==0.23.0->lang-sam==0.2.1) (0.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from supervision==0.23.0->lang-sam==0.2.1) (3.10.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from supervision==0.23.0->lang-sam==0.2.1) (1.15.1)\n",
      "Requirement already satisfied: filelock in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (3.17.0)\n",
      "Requirement already satisfied: sympy in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from torch==2.4.1->lang-sam==0.2.1) (3.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from transformers==4.44.2->lang-sam==0.2.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from transformers==4.44.2->lang-sam==0.2.1) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from transformers==4.44.2->lang-sam==0.2.1) (0.5.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from transformers==4.44.2->lang-sam==0.2.1) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from transformers==4.44.2->lang-sam==0.2.1) (4.67.1)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from gradio-client==1.4.0->gradio==5.0.2->lang-sam==0.2.1) (12.0)\n",
      "Requirement already satisfied: hydra-core>=1.3.2 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from sam-2@ git+https://github.com/facebookresearch/segment-anything-2@c2ec8e14a185632b0a5d8b161928ceb50197eddc->lang-sam==0.2.1) (1.3.2)\n",
      "Requirement already satisfied: iopath>=0.1.10 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from sam-2@ git+https://github.com/facebookresearch/segment-anything-2@c2ec8e14a185632b0a5d8b161928ceb50197eddc->lang-sam==0.2.1) (0.1.10)\n",
      "Requirement already satisfied: idna>=2.8 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio==5.0.2->lang-sam==0.2.1) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio==5.0.2->lang-sam==0.2.1) (1.3.1)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from fastapi<1.0->gradio==5.0.2->lang-sam==0.2.1) (0.45.3)\n",
      "Requirement already satisfied: certifi in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from httpx>=0.24.1->gradio==5.0.2->lang-sam==0.2.1) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from httpx>=0.24.1->gradio==5.0.2->lang-sam==0.2.1) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.0.2->lang-sam==0.2.1) (0.14.0)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from hydra-core>=1.3.2->sam-2@ git+https://github.com/facebookresearch/segment-anything-2@c2ec8e14a185632b0a5d8b161928ceb50197eddc->lang-sam==0.2.1) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from hydra-core>=1.3.2->sam-2@ git+https://github.com/facebookresearch/segment-anything-2@c2ec8e14a185632b0a5d8b161928ceb50197eddc->lang-sam==0.2.1) (4.9.3)\n",
      "Requirement already satisfied: portalocker in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from iopath>=0.1.10->sam-2@ git+https://github.com/facebookresearch/segment-anything-2@c2ec8e14a185632b0a5d8b161928ceb50197eddc->lang-sam==0.2.1) (3.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from matplotlib>=3.6.0->supervision==0.23.0->lang-sam==0.2.1) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from matplotlib>=3.6.0->supervision==0.23.0->lang-sam==0.2.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from matplotlib>=3.6.0->supervision==0.23.0->lang-sam==0.2.1) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from matplotlib>=3.6.0->supervision==0.23.0->lang-sam==0.2.1) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from matplotlib>=3.6.0->supervision==0.23.0->lang-sam==0.2.1) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from matplotlib>=3.6.0->supervision==0.23.0->lang-sam==0.2.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==5.0.2->lang-sam==0.2.1) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==5.0.2->lang-sam==0.2.1) (2025.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio==5.0.2->lang-sam==0.2.1) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio==5.0.2->lang-sam==0.2.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio==5.0.2->lang-sam==0.2.1) (13.9.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from uvicorn[standard]>=0.29.0->litserve==0.2.3->lang-sam==0.2.1) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from uvicorn[standard]>=0.29.0->litserve==0.2.3->lang-sam==0.2.1) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from uvicorn[standard]>=0.29.0->litserve==0.2.3->lang-sam==0.2.1) (1.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from requests->transformers==4.44.2->lang-sam==0.2.1) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from requests->transformers==4.44.2->lang-sam==0.2.1) (2.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from sympy->torch==2.4.1->lang-sam==0.2.1) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision==0.23.0->lang-sam==0.2.1) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.0.2->lang-sam==0.2.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.0.2->lang-sam==0.2.1) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.0.2->lang-sam==0.2.1) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/luca-medeiros/lang-segment-anything.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 1 masks\n",
      "Predicted 1 masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abka03/.conda/envs/lang_sam/lib/python3.11/site-packages/torchvision/transforms/functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from lang_sam import LangSAM\n",
    "\n",
    "model = LangSAM()\n",
    "image_pil = Image.open(\"/home/abka03/Projects/xl-vlms/playground/bus.jpg\").convert(\"RGB\")\n",
    "text_prompt = \"bus\"\n",
    "results = model.predict([image_pil], [text_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected objects: ['lunch', 'food']\n",
      "Predicting 1 masks\n",
      "Predicted 1 masks\n",
      "Predicting 1 masks\n",
      "Predicted 1 masks\n",
      "Segment 0: Label = lunch\n",
      "Segment 1: Label = lunch\n",
      "Segment 2: Label = lunch\n",
      "Segment 3: Label = food\n",
      "Segment 4: Label = food\n",
      "Segment 5: Label = food\n",
      "Segment 6: Label = food\n",
      "Segment 7: Label = food\n",
      "Segment 8: Label = food\n",
      "Segment 9: Label = food\n",
      "Segment 10: Label = food\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "from lang_sam import LangSAM\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "vqa_model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(device)\n",
    "\n",
    "\n",
    "def get_all_objects_vqa(image_pil):\n",
    "    \"\"\"Asks multiple questions to BLIP VQA to extract all possible objects in the image.\"\"\"\n",
    "    questions = [\n",
    "        \"What are the objects in the image?\",\n",
    "        \"List all the things present.\",\n",
    "        \"What items do you see?\",\n",
    "        \"Describe everything in the image.\",\n",
    "        \"What is inside this picture?\"\n",
    "    ]\n",
    "\n",
    "    detected_objects = set()  # Store unique objects\n",
    "\n",
    "    for question in questions:\n",
    "        inputs = processor(image_pil, question, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            out = vqa_model.generate(**inputs, max_length=500)\n",
    "            answer = processor.decode(out[0], skip_special_tokens=True)\n",
    "            detected_objects.update(answer.split(\",\"))  # Handle multiple objects\n",
    "\n",
    "    return list(detected_objects)  # Convert to list\n",
    "\n",
    "def vqa_and_segment(image_path):\n",
    "    # Load the image\n",
    "    image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "    image_np = np.array(image_pil)  # Convert image to numpy for processing\n",
    "    # Load the VQA model and processor\n",
    "\n",
    "\n",
    "    # Get the VQA model's answers\n",
    "     # Get a list of all objects in the image using multiple VQA questions\n",
    "    object_list = get_all_objects_vqa(image_pil)\n",
    "    print(\"Detected objects:\", object_list)\n",
    "\n",
    "    # Initialize LangSAM for segmentation\n",
    "    langsam_model = LangSAM()\n",
    "\n",
    "\n",
    "    # Segment the image based on the VQA answers\n",
    "    segmented_images = []\n",
    "    for  answer in object_list:\n",
    "        results = langsam_model.predict([image_pil], [answer])[0]\n",
    "        masks = results[\"masks\"]\n",
    "        labels = results[\"labels\"]\n",
    "        bboxes = results[\"boxes\"]  # Bounding boxes in (x1, y1, x2, y2) format\n",
    "\n",
    "        for i, (mask, label, bbox) in enumerate(zip(masks, labels, bboxes)):\n",
    "            x1, y1, x2, y2 = map(int, bbox)  # Convert bounding box coordinates to integers\n",
    "\n",
    "            # Convert mask to binary (0 or 255)\n",
    "            mask_np = (mask * 255).astype(np.uint8)\n",
    "\n",
    "            # Extract the bounding box region from the image and mask\n",
    "            cropped_image_np = image_np[y1:y2, x1:x2]\n",
    "            cropped_mask_np = mask_np[y1:y2, x1:x2]\n",
    "\n",
    "            # Apply mask to keep only the segmented object\n",
    "            segmented_np = np.zeros_like(cropped_image_np)\n",
    "            for c in range(3):  # Apply mask to all RGB channels\n",
    "                segmented_np[:, :, c] = cropped_image_np[:, :, c] * (cropped_mask_np // 255)\n",
    "\n",
    "            segmented_pil = Image.fromarray(segmented_np)\n",
    "            #segmented_pil = ImageOps.expand(segmented_pil, border=10, fill=\"white\")  # Optional padding\n",
    "            segmented_images.append((segmented_pil, label))\n",
    "            # Save the cropped segmented image\n",
    "    return segmented_images  # Return list of (PIL image, label)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"/home/abka03/Projects/xl-vlms/playground/datasets/coco8/images/train/000000000009.jpg\"\n",
    "\n",
    "segments = vqa_and_segment(image_path)\n",
    "save_path = \"/home/abka03/Projects/xl-vlms/playground/datasets/segmention\"\n",
    "# Display and print results\n",
    "for i, (segment_img, label) in enumerate(segments):\n",
    "    segment_filename = os.path.join(save_path, f\"{label}_{i}.png\")\n",
    "    segment_img.save(segment_filename)\n",
    "    #segment_img.show()  # Display each cropped segment\n",
    "    print(f\"Segment {i}: Label = {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4 images from /home/abka03/Projects/xl-vlms/playground/datasets/coco8/images/train...\n",
      "Detected objects in /home/abka03/Projects/xl-vlms/playground/datasets/coco8/images/train/000000000030.jpg: ['vase', 'flowers']\n",
      "Error processing /home/abka03/Projects/xl-vlms/playground/datasets/coco8/images/train/000000000030.jpg: The expanded size of the tensor (8) must match the existing size (4) at non-singleton dimension 2.  Target sizes: [4, 19947, 8].  Tensor sizes: [8, 1, 4]\n",
      "Detected objects in /home/abka03/Projects/xl-vlms/playground/datasets/coco8/images/train/000000000009.jpg: ['lunch', 'food']\n",
      "Error processing /home/abka03/Projects/xl-vlms/playground/datasets/coco8/images/train/000000000009.jpg: The expanded size of the tensor (8) must match the existing size (4) at non-singleton dimension 2.  Target sizes: [4, 17821, 8].  Tensor sizes: [8, 1, 4]\n",
      "Detected objects in /home/abka03/Projects/xl-vlms/playground/datasets/coco8/images/train/000000000025.jpg: ['giraffe', 'trees']\n",
      "Error processing /home/abka03/Projects/xl-vlms/playground/datasets/coco8/images/train/000000000025.jpg: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n",
      "Detected objects in /home/abka03/Projects/xl-vlms/playground/datasets/coco8/images/train/000000000034.jpg: ['zebra']\n",
      "Predicting 1 masks\n",
      "Predicted 1 masks\n",
      "Saved: /home/abka03/Projects/xl-vlms/playground/dataset/segments/zebra_0.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "from lang_sam import LangSAM\n",
    "\n",
    "# Check for GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load models once\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "vqa_model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(device)\n",
    "langsam_model = LangSAM()\n",
    "\n",
    "def get_all_objects_vqa(image_pil):\n",
    "    \"\"\"Extracts a list of objects from an image using VQA.\"\"\"\n",
    "    questions = [\n",
    "        \"What are the objects in the image?\",\n",
    "        \"List all the things present.\",\n",
    "        \"What items do you see?\",\n",
    "        \"Describe everything in the image.\",\n",
    "        \"What is inside this picture?\"\n",
    "    ]\n",
    "\n",
    "    detected_objects = set()  # Use a set to store unique objects\n",
    "\n",
    "    for question in questions:\n",
    "        inputs = processor(image_pil, question, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            out = vqa_model.generate(**inputs, max_length=500)\n",
    "            answer = processor.decode(out[0], skip_special_tokens=True)\n",
    "            detected_objects.update(obj.lower().strip() for obj in answer.split(\",\"))  # Normalize text\n",
    "\n",
    "    return list(detected_objects)\n",
    "\n",
    "def vqa_and_segment(image_path):\n",
    "    \"\"\"Processes an image, extracts objects, and segments them as a batch. Returns a list of (image, label, index).\"\"\"\n",
    "    try:\n",
    "        # Load and convert the image\n",
    "        image_pil = Image.open(image_path).convert(\"RGB\")\n",
    "        image_np = np.array(image_pil)\n",
    "\n",
    "        # Get detected objects using VQA\n",
    "        object_list = get_all_objects_vqa(image_pil)\n",
    "        print(f\"Detected objects in {image_path}: {object_list}\")\n",
    "\n",
    "        # Batch processing: Predict segmentation for all detected objects at once\n",
    "        results = langsam_model.predict([image_pil], object_list)[0]\n",
    "        masks, labels, bboxes = results[\"masks\"], results[\"labels\"], results[\"boxes\"]\n",
    "\n",
    "        segmented_results = []\n",
    "        for i, (mask, label, bbox) in enumerate(zip(masks, labels, bboxes)):\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "\n",
    "            # Convert mask to binary format\n",
    "            mask_np = (mask * 255).astype(np.uint8)\n",
    "\n",
    "            # Extract relevant region\n",
    "            cropped_image_np = image_np[y1:y2, x1:x2]\n",
    "            cropped_mask_np = mask_np[y1:y2, x1:x2]\n",
    "\n",
    "            # Apply mask to retain segmented object\n",
    "            segmented_np = np.zeros_like(cropped_image_np)\n",
    "            for c in range(3):  # Apply mask to all RGB channels\n",
    "                segmented_np[:, :, c] = cropped_image_np[:, :, c] * (cropped_mask_np // 255)\n",
    "\n",
    "            segmented_pil = Image.fromarray(segmented_np)\n",
    "            segmented_results.append((segmented_pil, label, i))\n",
    "\n",
    "        return segmented_results  # List of (PIL image, label, index)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_images_in_folder(folder_path):\n",
    "    \"\"\"Processes all images in a folder and returns segmentation results.\"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(\"Error: Folder does not exist.\")\n",
    "        return {}\n",
    "\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No images found in the folder.\")\n",
    "        return {}\n",
    "\n",
    "    print(f\"Processing {len(image_files)} images from {folder_path}...\")\n",
    "\n",
    "    all_segments = {}\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        all_segments[image_path] = vqa_and_segment(image_path)\n",
    "\n",
    "    return all_segments  # Dictionary {image_path: [(image, label, index), ...]}\n",
    "\n",
    "# Example usage\n",
    "image_folder = \"/home/abka03/Projects/xl-vlms/playground/datasets/coco8/images/train\"\n",
    "save_folder = \"/home/abka03/Projects/xl-vlms/playground/dataset/segments\"\n",
    "\n",
    "segmentation_results = process_images_in_folder(image_folder)\n",
    "\n",
    "# Save segmented images outside the function\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "for image_path, segments in segmentation_results.items():\n",
    "    for segment_img, label, index in segments:\n",
    "        filename = f\"{label}_{index}.png\"\n",
    "        save_path = os.path.join(save_folder, filename)\n",
    "        segment_img.save(save_path)\n",
    "        print(f\"Saved: {save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
