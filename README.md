# XL-VLMs: general repository for explainable large vision language models


# News


# Installation

Required libraries:

```
torch==1.13.1
transformers==4.45.1
accelerate==0.34.2
scikit-learn==1.5.2
```

# Usage

## Datasets
We support the following datasets:
* COCO

## Models

We support models from the `transformers` library. Currently we support the following:
* LLaVA-1.5

# Contributing


## Saving hidden states


# Citation
```
```
